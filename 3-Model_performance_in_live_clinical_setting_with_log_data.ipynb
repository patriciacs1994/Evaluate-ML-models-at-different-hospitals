{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41822f4",
   "metadata": {},
   "source": [
    "# Log data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4b33a",
   "metadata": {},
   "source": [
    "## Prepare the log data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246c37d",
   "metadata": {},
   "source": [
    "### 1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab27125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20dbe00",
   "metadata": {},
   "source": [
    "### 2. Provide some general information about the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General input\n",
    "use_case = 'aki'\n",
    "\n",
    "# HDZ\n",
    "date_logs =['20210219', '20210226', '20210305','20210319','20210409','20210416','20210507','20210521','20210528','20210604','20210611','20210618','20210625']\n",
    "\n",
    "customer = 'HDZ'\n",
    "path = r'logs'\n",
    "path_log_file = f'{path}/{customer}/{date_logs[-1]}'\n",
    "\n",
    "#Last outcome file path\n",
    "path_outcome_file = f'{path_log_file}/{date_logs[-1]}_{customer.lower()}_{use_case[0:3]}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data of outcome is extracted from the path of outcome file\n",
    "outcome_date = pd.to_datetime(path_outcome_file[-20:-12], format=\"%Y%m%d\")\n",
    "\n",
    "# Define Code deadline as 60 days before the end date\n",
    "code_deadline = outcome_date - timedelta(days = 60 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76866c5",
   "metadata": {},
   "source": [
    "### 3. Read in the log file and create a dataframe with all observation in the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f803ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_log=[]\n",
    "\n",
    "for date_log in date_logs:\n",
    "    with open(f'{path}/{customer}/{date_log}/{customer}_{date_log}-{use_case[0:3]}-model.log', \"r\") as log:\n",
    "        for line in log:\n",
    "            aggregated_log.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe6373",
   "metadata": {},
   "source": [
    "### 4. Extract the predictions from the RESPONSE line in the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.DataFrame(columns=['CASEID','DATE', 'OBS','BELIEF'])\n",
    "cases=[]\n",
    "beliefs = []\n",
    "observations = []\n",
    "dates=[]\n",
    "for line in aggregated_log:\n",
    "    if re.search('RESPONSE',line):\n",
    "        step1 = re.sub('^.* RESPONSE ','',line)\n",
    "        step2 = re.sub('\\\\\\\\n\".*$','',step1)\n",
    "        step3 = re.sub('^.*:\"','',line)[:19]\n",
    "        \n",
    "        step5 = line.replace(\"\\\\\",\"\")\n",
    "        obs = re.sub('}n',': ',step5).split('\": \"')[2]\n",
    "        result = re.sub('\\n', '', step2)\n",
    "        case = result.split(': ')[0]\n",
    "        belief = result.split(': ')[2].split(',')[0]\n",
    "        cases.append(case)\n",
    "        \n",
    "        if ('DELIRIUM 1' in line )| ('SEPSIS 1' in line )|('AKI 1' in line ):\n",
    "            beliefs.append(math.exp(float(belief)))\n",
    "        else:\n",
    "            beliefs.append(1-math.exp(float(belief)))        \n",
    "        \n",
    "        dates.append(step3)\n",
    "        observations.append(obs)\n",
    "            \n",
    "prediction_data.CASEID = cases\n",
    "prediction_data.BELIEF = beliefs  \n",
    "prediction_data.DATE = dates\n",
    "prediction_data.OBS = observations\n",
    "prediction_data = prediction_data.sort_values(['CASEID','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f760066",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = prediction_data.drop_duplicates()\n",
    "prediction_data['CASEID'] = prediction_data['CASEID'].astype(int)\n",
    "prediction_data['DATETIME'] = pd.to_datetime(prediction_data['DATE'], format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# date only on day level\n",
    "prediction_data['DATE'] = prediction_data['DATETIME'].apply(lambda x: x.date())\n",
    "\n",
    "# for predictions that belong to the same medical case and have same observations and belief, take just the last instance.\n",
    "prediction_data['DATETIME'] = prediction_data.groupby(['CASEID','DATE','OBS','BELIEF'])['DATETIME'].transform(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af198a00",
   "metadata": {},
   "source": [
    "### 5. Merge the prediction_data with the outcome file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_file = pd.read_csv(path_outcome_file,  sep = ';')\n",
    "outcome_file = outcome_file[~outcome_file.CANCELDATE.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d73b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign label to the prediction data \n",
    "prediction_data['LABEL'] = np.where(prediction_data['CASEID'].isin(outcome_file.FALLID),1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609543e",
   "metadata": {},
   "source": [
    "### 6. Log data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check period of the logs\n",
    "start_date = prediction_data.DATETIME.min().floor('D')\n",
    "end_date = prediction_data.DATETIME.max().floor('D')\n",
    "\n",
    "print(start_date)\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbaa595",
   "metadata": {},
   "source": [
    "### 6.1. Read all the discharged cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31897fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include all the discharged cases\n",
    "dis_logs = date_logs\n",
    "discharged_df_total = pd.DataFrame(columns=['FALLID','AUFNDAT','ENTLDAT'])\n",
    "parser = lambda x: pd.datetime.strptime(x[0:10], '%d.%m.%Y')\n",
    "dtypes = {'FALLID':int, 'AUFNDAT':str, 'ENTLDAT':str}\n",
    "\n",
    "for dis_log in dis_logs:\n",
    "    discharged_file1 = pd.read_csv(f'{path}/{customer}/{dis_log}/{dis_log}_{customer.lower()}_discharges.txt',  sep = ';', dtype = dtypes , parse_dates=['AUFNDAT', 'ENTLDAT'], date_parser=parser)\n",
    "    discharged_df_total = pd.concat([discharged_file1, discharged_df_total])\n",
    "discharged_file = discharged_df_total.drop_duplicates(subset=\"FALLID\")\n",
    "open_cases_file = pd.read_csv(f'{path}/{customer}/{date_logs[-1]}/{date_logs[-1]}_{customer.lower()}_open_cases.txt',  sep = ';', dtype = dtypes , parse_dates=['AUFNDAT'], date_parser=parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396fabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a case is discharged more than 60 days before the outcome file, it is considered as coded\n",
    "coded_cases = discharged_file[discharged_file.ENTLDAT<code_deadline].FALLID\n",
    "\n",
    "# If a case is considered as coded, keep the label, otherwise, set the label as -1, meaning unknown\n",
    "prediction_data['LABEL'] = np.where(prediction_data.CASEID.isin(coded_cases), prediction_data['LABEL'],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc92f58",
   "metadata": {},
   "source": [
    "### 6.2. Categorize the cases in [\"admitted in the log\", \"discharged in the log\", \"admitted and discharged in the log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69efbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_adm is defeined as cases that are admitted and discharged (subset of cases_dis).\n",
    "# open_cases is defined as cases that are admitted during the log period and is not yet closed.\n",
    "# Those admitted during the period is the merge of the above two sets.\n",
    "# cases_dis is defined as cases that are discharged during the log period.\n",
    "cases_adm = discharged_file[(discharged_file.AUFNDAT >= start_date) & (discharged_file.AUFNDAT <= end_date)].FALLID.unique().tolist()\n",
    "cases_dis = discharged_file[discharged_file.ENTLDAT <= end_date].FALLID.unique().tolist()\n",
    "open_cases = open_cases_file[(open_cases_file.AUFNDAT >= start_date) & (open_cases_file.AUFNDAT <= end_date)].FALLID.unique().tolist()\n",
    "\n",
    "admission_df = prediction_data[prediction_data.CASEID.isin(cases_adm) | prediction_data.CASEID.isin(open_cases)].reset_index(drop=True)\n",
    "\n",
    "discharged_df = prediction_data[prediction_data.CASEID.isin(cases_dis)].reset_index(drop=True)\n",
    "discharged_df = discharged_df.reset_index()\n",
    "\n",
    "# for admission df, only take the last instance of the first day. \n",
    "# for discharge df, only take the last instance of the last day.\n",
    "admission_df = admission_df[admission_df.groupby(['CASEID'])['DATE'].transform(min)==admission_df['DATE']]\n",
    "admission_df = admission_df[admission_df.groupby(['CASEID'])['DATETIME'].transform(max)==admission_df['DATETIME']]\n",
    "admission_df = admission_df.drop_duplicates(subset='CASEID', keep=\"last\")\n",
    "\n",
    "discharged_df = discharged_df[discharged_df.groupby(['CASEID'])['DATETIME'].transform(max)==discharged_df['DATETIME']]\n",
    "discharged_df = discharged_df.drop_duplicates(subset='CASEID', keep=\"last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99930b21",
   "metadata": {},
   "source": [
    "### 6.3. Calculate the alert rates at admission and at discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison alerts at admission and at discharge\n",
    "step = admission_df[admission_df['BELIEF'] >= 0.5]\n",
    "med_A = len(step[step['BELIEF'] < 0.75])\n",
    "high_A = len(step[step['BELIEF'] >= 0.75])\n",
    "alert_rate_A_M = \"{:.1%}\".format((med_A) / len(admission_df))\n",
    "alert_rate_A_H = \"{:.1%}\".format((high_A) / len(admission_df))\n",
    "\n",
    "step = discharged_df[discharged_df['BELIEF'] >= 0.5]\n",
    "med_D = len(step[step['BELIEF'] < 0.75])\n",
    "high_D = len(step[step['BELIEF'] >= 0.75])\n",
    "alert_rate_D_M = \"{:.1%}\".format((med_D) / len(discharged_df))\n",
    "alert_rate_D_H = \"{:.1%}\".format((high_D) / len(discharged_df))\n",
    "\n",
    "matrix_comp = pd.DataFrame(columns=['at admission', 'at discharge'], index=[\n",
    "                           'amount of cases', 'amount of positive predicted cases', 'med risk', 'high risk', 'alert rate medium risk', 'alert_rate_high_risk'])\n",
    "matrix_comp['at admission'] = [len(admission_df), len(admission_df[admission_df['BELIEF'] >= 0.5]), med_A, high_A, alert_rate_A_M, alert_rate_A_H]\n",
    "matrix_comp['at discharge'] = [len(discharged_df), len(discharged_df[discharged_df['BELIEF'] >= 0.5]), med_D, high_D, alert_rate_D_M, alert_rate_D_H]\n",
    "matrix_comp.to_csv(f'{path_log_file}/{use_case}/matrix_comparative.csv', index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18125b50",
   "metadata": {},
   "source": [
    "### 6.4. Calculate the alert rates per department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67d1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comparison alerts rates per department at admission and at discharge \n",
    "# Read table departments file\n",
    "departments = pd.read_csv(f'{path}/{customer}/departments.csv', sep=',', dtype ='str', header=None)\n",
    "departments = departments.rename(columns={0: 'F', 1: 'DESCRIPTION'})\n",
    "departments['F'] = 'DEPARTMENT-' + departments.F\n",
    "  \n",
    "admission_df['OBS_SPLIT'] = admission_df.apply(lambda x: x.OBS.split(' '), axis=1)\n",
    "admission_df['DEPARTMENT'] = admission_df.OBS_SPLIT.apply(lambda x: [f for f in x if f.startswith('DEPARTMENT')])\n",
    "admission_df_dep = admission_df.explode('DEPARTMENT')\n",
    "admission_df_dep = admission_df_dep.sort_values(by = ['DEPARTMENT']).reset_index(drop = True)\n",
    "\n",
    "count = len(admission_df_dep.CASEID.unique().tolist())\n",
    "department_list = admission_df_dep['DEPARTMENT'].unique().tolist()\n",
    "alert_rate_first_dep_M = []\n",
    "alert_rate_first_dep_H = []\n",
    "count_first = []\n",
    "\n",
    "discharged_df['OBS_SPLIT'] = discharged_df.apply(lambda x: x.OBS.split(' '), axis=1)\n",
    "discharged_df['DEPARTMENT'] = discharged_df.OBS_SPLIT.apply(lambda x: [f for f in x if f.startswith('DEPARTMENT')])\n",
    "\n",
    "discharged_df_dep = discharged_df.explode('DEPARTMENT')\n",
    "discharged_df_dep = discharged_df_dep.sort_values(by = ['DEPARTMENT']).reset_index(drop = True)\n",
    "count_L = len(discharged_df_dep.CASEID.unique().tolist())\n",
    "department_list = discharged_df_dep['DEPARTMENT'].unique().tolist()\n",
    "alert_rate_last_dep_M = []\n",
    "alert_rate_last_dep_H = []\n",
    "count_last = []\n",
    "total_alert_rate_first=[]\n",
    "total_alert_rate_last=[]\n",
    "\n",
    "for dep in department_list:\n",
    "    dep_df = admission_df_dep[admission_df_dep['DEPARTMENT'] == dep]\n",
    "    if len(dep_df) > 0:\n",
    "        step = dep_df[dep_df['BELIEF'] >= 0.5]\n",
    "        med = len(step[step['BELIEF'] < 0.75])\n",
    "        high = len(step[step['BELIEF'] >= 0.75])\n",
    "        alert_rate_first_dep_M.append(\"{:.1%}\".format((med) / len(dep_df)))\n",
    "        alert_rate_first_dep_H.append(\"{:.1%}\".format((high) / len(dep_df)))\n",
    "        total_alert_rate_first.append(\"{:.1%}\".format(len(step)/len(dep_df)))\n",
    "    else:\n",
    "        alert_rate_first_dep_M.append(\"0.0%\")\n",
    "        alert_rate_first_dep_H.append(\"0.0%\")\n",
    "    count_first.append(len(dep_df.CASEID.unique().tolist()))\n",
    "\n",
    "for dep in department_list:\n",
    "    dep_df = discharged_df_dep[discharged_df_dep['DEPARTMENT'] == dep]\n",
    "    if len(dep_df) > 0:\n",
    "        step = dep_df[dep_df['BELIEF'] >= 0.5]\n",
    "        med = len(step[step['BELIEF'] < 0.75])\n",
    "        high = len(step[step['BELIEF'] >= 0.75])\n",
    "        alert_rate_last_dep_M.append(\"{:.1%}\".format((med) / len(dep_df)))\n",
    "        alert_rate_last_dep_H.append(\"{:.1%}\".format((high) / len(dep_df)))\n",
    "        total_alert_rate_last.append(\"{:.1%}\".format(len(step)/len(dep_df)))\n",
    "    else:\n",
    "        alert_rate_last_dep_M.append(\"0.0%\")\n",
    "        alert_rate_last_dep_H.append(\"0.0%\")\n",
    "    count_last.append(len(dep_df.CASEID.unique().tolist()))\n",
    "    \n",
    "matrix_alert_rate = pd.DataFrame(columns=['department_code', 'count_adm','total_alerts_A', 'AR_A_M', 'AR_A_H', 'count_dis', 'total_alerts_D','AR_D_M', 'AR_D_H'])\n",
    "counts_F = count * np.ones(len(count_first))\n",
    "counts_L = count_L * np.ones(len(count_last))\n",
    "matrix_alert_rate['AR_A_M'] = alert_rate_first_dep_M\n",
    "matrix_alert_rate['AR_A_H'] = alert_rate_first_dep_H\n",
    "matrix_alert_rate['AR_D_M'] = alert_rate_last_dep_M\n",
    "matrix_alert_rate['AR_D_H'] = alert_rate_last_dep_H\n",
    "matrix_alert_rate['department_code'] = department_list\n",
    "matrix_alert_rate['total_alerts_A'] = total_alert_rate_first\n",
    "matrix_alert_rate['total_alerts_D'] = total_alert_rate_last\n",
    "matrix_alert_rate['count_dis'] = count_last\n",
    "matrix_alert_rate['count_adm'] = count_first\n",
    "ratio_dis = count_last/counts_L\n",
    "ratio_adm = count_first/counts_F\n",
    "\n",
    "matrix_alert_rate = matrix_alert_rate.rename(columns={'department_code': 'F'})\n",
    "matrix_alert_rate = matrix_alert_rate.merge(departments, on='F', how='left')\n",
    "matrix_alert_rate = matrix_alert_rate.rename(columns={'F': 'department_code'})\n",
    "matrix_alert_rate = matrix_alert_rate.rename(columns={'DESCRIPTION': 'department'})\n",
    "matrix_alert_rate = matrix_alert_rate.sort_values(by='count_dis', ascending = False).reset_index(drop=True)\n",
    "matrix_alert_rate.to_csv(f'{path_log_file}/{use_case}/matrix_alert_rate.csv', index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb8953",
   "metadata": {},
   "source": [
    "### 6.5. Calculate metrics per departments\n",
    "Calculate sensitivity, specificity, ppv, auroc per department. Only include the responses that have been discharged 60 days before the last outcome file and admitted in the log period (start_date - end_date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f92d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate metrics for each medical case\n",
    "#If a medical case has at least one high risk alert then is considered as a positive prediction.\n",
    "log_df = prediction_data.drop(prediction_data[prediction_data.LABEL == -1].index)\n",
    "log_df['OBS_SPLIT'] = log_df.apply(lambda x: x.OBS.split(' '), axis=1)\n",
    "log_df['DEPARTMENT'] = log_df.OBS_SPLIT.apply(lambda x: [f for f in x if f.startswith('DEPARTMENT')])\n",
    "log_df['PREDICTION_M'] = np.where(log_df['BELIEF'] >= 0.5,1,0)\n",
    "log_df['PREDICTION_H'] = np.where(log_df['BELIEF'] >= 0.75,1,0)\n",
    "\n",
    "log_df_dep = log_df.explode('DEPARTMENT')\n",
    "log_df_dep = log_df_dep.sort_values(by = ['DEPARTMENT']).reset_index(drop = True)\n",
    "log_df_dep = log_df_dep.groupby(by=[\"CASEID\",\"DEPARTMENT\"])[[\"CASEID\",\"LABEL\",\"PREDICTION_M\",\"PREDICTION_H\",'DEPARTMENT','OBS_SPLIT','BELIEF']].max()\n",
    "department_list = log_df_dep['DEPARTMENT'].unique().tolist()\n",
    "\n",
    "total_cases = []\n",
    "pos_cases =[]\n",
    "sensitivity_M = []\n",
    "specificity_M = []\n",
    "ppv_M = []\n",
    "sensitivity_H = []\n",
    "specificity_H = []\n",
    "ppv_H = []\n",
    "incidence = []\n",
    "for dep in department_list:\n",
    "    dep_df = log_df_dep[log_df_dep['DEPARTMENT'] == dep]\n",
    "    tn, fp, fn, tp = confusion_matrix(dep_df.LABEL, dep_df.PREDICTION_M).ravel()\n",
    "    specificity_M.append(tn / (tn+fp))\n",
    "    sensitivity_M.append(tp / (tp+fn))\n",
    "    ppv_M.append(tp / (tp+fp))\n",
    "    tn, fp, fn, tp = confusion_matrix(dep_df.LABEL, dep_df.PREDICTION_H).ravel()\n",
    "    specificity_H.append(tn / (tn+fp))\n",
    "    sensitivity_H.append(tp / (tp+fn))\n",
    "    ppv_H.append(tp / (tp+fp))\n",
    "    incidence.append(\"{:.1%}\".format(len(dep_df[dep_df[\"LABEL\"]==1].CASEID.unique().tolist())/len(dep_df.CASEID.unique().tolist())))\n",
    "    total_cases.append(len(dep_df.CASEID.unique().tolist()))\n",
    "    pos_cases.append(len(dep_df[dep_df[\"LABEL\"]==1].CASEID.unique().tolist()))\n",
    "\n",
    "metrics_per_department_mc = pd.DataFrame(columns=['department_code', 'total_cases','pos_cases','incidence','sensitivity_M','specificity_M','ppv_M','sensitivity_H','specificity_H','ppv_H'])\n",
    "metrics_per_department_mc['department_code'] = department_list\n",
    "metrics_per_department_mc['total_cases'] = total_cases\n",
    "metrics_per_department_mc['pos_cases'] = pos_cases\n",
    "metrics_per_department_mc['incidence'] = incidence\n",
    "metrics_per_department_mc['sensitivity_M'] = sensitivity_M\n",
    "metrics_per_department_mc['specificity_M'] = specificity_M\n",
    "metrics_per_department_mc['ppv_M'] = ppv_M\n",
    "metrics_per_department_mc['sensitivity_H'] = sensitivity_H\n",
    "metrics_per_department_mc['specificity_H'] = specificity_H\n",
    "metrics_per_department_mc['ppv_H'] = ppv_H\n",
    "metrics_per_department_mc = metrics_per_department_mc.sort_values(by='total_cases', ascending = False).reset_index(drop=True)\n",
    "metrics_per_department_mc.to_csv(f'{path_log_file}/{use_case}/metrics_per_department.csv', index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd91da",
   "metadata": {},
   "source": [
    "### 6.6. Calculate metrics of all medical cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3577dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = prediction_data.drop(prediction_data[prediction_data.LABEL == -1].index)\n",
    "log_df['OBS_SPLIT'] = log_df.apply(lambda x: x.OBS.split(' '), axis=1)\n",
    "log_df['DEPARTMENT'] = log_df.OBS_SPLIT.apply(lambda x: [f for f in x if f.startswith('DEPARTMENT')])\n",
    "log_df['PREDICTION_M'] = np.where(log_df['BELIEF'] >= 0.5,1,0)\n",
    "log_df['PREDICTION_H'] = np.where(log_df['BELIEF'] >= 0.75,1,0)\n",
    "log_df_all = log_df.groupby(by=[\"CASEID\"])[[\"CASEID\",\"LABEL\",\"PREDICTION_M\",\"PREDICTION_H\",'DEPARTMENT','OBS_SPLIT','BELIEF']].max()\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(log_df_all.LABEL, log_df_all.PREDICTION_M).ravel()\n",
    "specificity_M = (tn / (tn+fp))\n",
    "sensitivity_M = (tp / (tp+fn))\n",
    "ppv_M = (tp / (tp+fp))\n",
    "tn, fp, fn, tp = confusion_matrix(log_df_all.LABEL, log_df_all.PREDICTION_H).ravel()\n",
    "specificity_H = (tn / (tn+fp))\n",
    "sensitivity_H = (tp / (tp+fn))\n",
    "ppv_H = (tp / (tp+fp))\n",
    "incidence = \"{:.1%}\".format(len(log_df_all[log_df_all[\"LABEL\"]==1].CASEID.unique().tolist())/len(log_df_all.CASEID.unique().tolist()))\n",
    "total_cases = len(log_df_all.CASEID.unique().tolist())\n",
    "pos_cases = len(log_df_all[log_df_all[\"LABEL\"]==1].CASEID.unique().tolist())\n",
    "auroc_score = roc_auc_score(log_df_all.LABEL, log_df_all.BELIEF)\n",
    "    \n",
    "metrics_all = pd.DataFrame(columns=['total_cases','pos_cases','incidence','sensitivity_M','specificity_M','ppv_M','sensitivity_H','specificity_H','ppv_H'])\n",
    "metrics_all['total_cases'] = [total_cases]\n",
    "metrics_all['pos_cases'] = pos_cases\n",
    "metrics_all['incidence'] = incidence\n",
    "metrics_all['sensitivity_M'] = sensitivity_M\n",
    "metrics_all['specificity_M'] = specificity_M\n",
    "metrics_all['ppv_M'] = ppv_M\n",
    "metrics_all['sensitivity_H'] = sensitivity_H\n",
    "metrics_all['specificity_H'] = specificity_H\n",
    "metrics_all['ppv_H'] = ppv_H\n",
    "metrics_all['AUROC'] = auroc_score\n",
    "metrics_all.to_csv(f'{path_log_file}/{use_case}/metrics_all_cases.csv', index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe065d6",
   "metadata": {},
   "source": [
    "### 6.7. Calculate metrics for all medical cases at discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23dbca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "discharged_df = discharged_df.drop(discharged_df[discharged_df.LABEL == -1].index)\n",
    "discharged_df['OBS_SPLIT'] = discharged_df.apply(lambda x: x.OBS.split(' '), axis=1)\n",
    "discharged_df['DEPARTMENT'] = discharged_df.OBS_SPLIT.apply(lambda x: [f for f in x if f.startswith('DEPARTMENT')])\n",
    "discharged_df['PREDICTION_M'] = np.where(discharged_df['BELIEF'] >= 0.5,1,0)\n",
    "discharged_df['PREDICTION_H'] = np.where(discharged_df['BELIEF'] >= 0.75,1,0)\n",
    "discharged_df_all = discharged_df.groupby(by=[\"CASEID\"])[[\"CASEID\",\"LABEL\",\"PREDICTION_M\",\"PREDICTION_H\",'DEPARTMENT','OBS_SPLIT','BELIEF']].max()\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(discharged_df_all.LABEL, discharged_df_all.PREDICTION_M).ravel()\n",
    "specificity_M = (tn / (tn+fp))\n",
    "sensitivity_M = (tp / (tp+fn))\n",
    "ppv_M = (tp / (tp+fp))\n",
    "tn, fp, fn, tp = confusion_matrix(discharged_df_all.LABEL, discharged_df_all.PREDICTION_H).ravel()\n",
    "specificity_H = (tn / (tn+fp))\n",
    "sensitivity_H = (tp / (tp+fn))\n",
    "ppv_H = (tp / (tp+fp))\n",
    "incidence = \"{:.1%}\".format(len(discharged_df_all[discharged_df_all[\"LABEL\"]==1].CASEID.unique().tolist())/len(discharged_df_all.CASEID.unique().tolist()))\n",
    "total_cases = len(discharged_df_all.CASEID.unique().tolist())\n",
    "pos_cases = len(discharged_df_all[discharged_df_all[\"LABEL\"]==1].CASEID.unique().tolist())\n",
    "auroc_score = roc_auc_score(discharged_df_all.LABEL, discharged_df_all.BELIEF)\n",
    " \n",
    "metrics_dis_all = pd.DataFrame(columns=['total_cases','pos_cases','incidence','sensitivity_M','specificity_M','ppv_M','sensitivity_H','specificity_H','ppv_H'])\n",
    "metrics_dis_all['total_cases'] = [total_cases]\n",
    "metrics_dis_all['pos_cases'] = pos_cases\n",
    "metrics_dis_all['incidence'] = incidence\n",
    "metrics_dis_all['sensitivity_M'] = sensitivity_M\n",
    "metrics_dis_all['specificity_M'] = specificity_M\n",
    "metrics_dis_all['ppv_M'] = ppv_M\n",
    "metrics_dis_all['sensitivity_H'] = sensitivity_H\n",
    "metrics_dis_all['specificity_H'] = specificity_H\n",
    "metrics_dis_all['ppv_H'] = ppv_H\n",
    "metrics_dis_all['AUROC'] = auroc_score\n",
    "metrics_dis_all.to_csv(f'{path_log_file}/{use_case}/metrics_dis_all_cases.csv', index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f6eec",
   "metadata": {},
   "source": [
    "### 6.8. Calculate metrics for all medical cases at admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_df = admission_df.drop(admission_df[admission_df.LABEL == -1].index)\n",
    "admission_df['OBS_SPLIT'] = admission_df.apply(lambda x: x.OBS.split(' '), axis=1)\n",
    "admission_df['DEPARTMENT'] = admission_df.OBS_SPLIT.apply(lambda x: [f for f in x if f.startswith('DEPARTMENT')])\n",
    "admission_df['PREDICTION_M'] = np.where(admission_df['BELIEF'] >= 0.5,1,0)\n",
    "admission_df['PREDICTION_H'] = np.where(admission_df['BELIEF'] >= 0.75,1,0)\n",
    "admission_df_all = admission_df.groupby(by=[\"CASEID\"])[[\"CASEID\",\"LABEL\",\"PREDICTION_M\",\"PREDICTION_H\",'DEPARTMENT','OBS_SPLIT','BELIEF']].max()\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(admission_df_all.LABEL, admission_df_all.PREDICTION_M).ravel()\n",
    "specificity_M = (tn / (tn+fp))\n",
    "sensitivity_M = (tp / (tp+fn))\n",
    "ppv_M = (tp / (tp+fp))\n",
    "tn, fp, fn, tp = confusion_matrix(admission_df_all.LABEL, admission_df_all.PREDICTION_H).ravel()\n",
    "specificity_H = (tn / (tn+fp))\n",
    "sensitivity_H = (tp / (tp+fn))\n",
    "ppv_H = (tp / (tp+fp))\n",
    "incidence = \"{:.1%}\".format(len(admission_df_all[admission_df_all[\"LABEL\"]==1].CASEID.unique().tolist())/len(admission_df_all.CASEID.unique().tolist()))\n",
    "total_cases = len(admission_df_all.CASEID.unique().tolist())\n",
    "pos_cases = len(admission_df_all[admission_df_all[\"LABEL\"]==1].CASEID.unique().tolist())\n",
    "auroc_score = roc_auc_score(admission_df_all.LABEL, admission_df_all.BELIEF)\n",
    "    \n",
    "metrics_adm_all = pd.DataFrame(columns=['total_cases','pos_cases','incidence','sensitivity_M','specificity_M','ppv_M','sensitivity_H','specificity_H','ppv_H'])\n",
    "metrics_adm_all['total_cases'] = [total_cases]\n",
    "metrics_adm_all['pos_cases'] = pos_cases\n",
    "metrics_adm_all['incidence'] = incidence\n",
    "metrics_adm_all['sensitivity_M'] = sensitivity_M\n",
    "metrics_adm_all['specificity_M'] = specificity_M\n",
    "metrics_adm_all['ppv_M'] = ppv_M\n",
    "metrics_adm_all['sensitivity_H'] = sensitivity_H\n",
    "metrics_adm_all['specificity_H'] = specificity_H\n",
    "metrics_adm_all['ppv_H'] = ppv_H\n",
    "metrics_adm_all['AUROC'] = auroc_score\n",
    "metrics_adm_all.to_csv(f'{path_log_file}/{use_case}/metrics_adm_all_cases.csv', index = False, sep = \";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
